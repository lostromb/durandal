import "Durandal.BondProtocol.API.AudioData.bond"
import "Durandal.BondProtocol.API.ClientContext.bond"
import "Durandal.BondProtocol.API.RecoResult.bond"
import "Durandal.BondProtocol.API.InputMethod.bond"
import "Durandal.BondProtocol.API.RecognizedPhrase.bond"
import "Durandal.BondProtocol.API.SecurityToken.bond"
import "Durandal.BondProtocol.API.SpeechRecognitionResult.bond"
import "Durandal.BondProtocol.API.EntityReference.bond"

namespace Durandal.Extensions.BondProtocol.API

struct DialogRequest
{
    // Versioning for this communication
	1: required int32 ProtocolVersion = 20;
	
	// The client context specific to this request
	2: required ClientContext ClientContext;
	
	// Defines the method of input used to generate this request
	3: required InputMethod InteractionType = Unknown;
	
	// Input string if input method is text
	4: nullable<string> TextInput;
	
	// Speech recognition result if input method is speech
	5: nullable<SpeechRecognitionResult> SpeechInput;
	
	// Optional security token information
	6: nullable<vector<SecurityToken>> AuthTokens;
	
	// If the client cannot do speech reco, it will simply pass the audio here
	7: nullable<AudioData> AudioInput;
	
	// If the client wishes to invoke a dialog action directly it can do so here
	// This can also be used if LU was invoked elsewhere and we want to bypass the
	// LU call that normally happens in dialog
	8: nullable<vector<RecognizedPhrase>> LanguageUnderstanding;
	
	// The preferred audio codec that the client wants the response audio to use
	9: nullable<string> PreferredAudioCodec;
	
	// A debugging traceId. If not set, a new one will be generated
	10: nullable<string> TraceId;
	
	// Used to scope the client request to only a subset of loaded domains
	11: nullable<vector<string>> DomainScope;

	// If the user gave more input while the response from the previous turn is still
	// playing out of their speakers, this client should set this field
	// which indicates how much of the response was actually played, in ms.
	// This is to allow barge-in selection if the answer supports it.
	12: nullable<int32> ClientAudioPlaybackTimeMs;

	// Stores flags that identify the type of request.
	// Common flags might be for debug, trace, etc.
	13: uint32 RequestFlags = 0;
	
	// Entity context for storing input entities to be sent to dialog
	14: blob EntityContext;
	
	// List of entity IDs for entities to be passed to dialog
	15: nullable<vector<EntityReference>> EntityInput;
	
	// A map of arbitrary data which is used for SPA, client resolution, and similar scenarios
	16: nullable<map<string, string>> RequestData;
	
	// A string representing the preferred audio encoding of the client. A typical format is "samplerate=16000 channels=1 layout=1"
	17: nullable<string> PreferredAudioFormat;
}